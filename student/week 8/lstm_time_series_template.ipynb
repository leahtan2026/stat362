{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "id": "k6jA5HECHNt1",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Quiz 12: Time Series Forecasting with Neural Networks\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-zFmVZ-HNt2"
   },
   "source": [
    "\n",
    "\n",
    "Recurrent neural networks (**RNNs**), especially **LSTMs**, are powerful for modeling sequence data and time series. In this lab, you'll build a univariate time series predictor. (In HW2, you'll extend this to multivariate forecasting.)\n",
    "\n",
    "What you'll do:\n",
    "\n",
    "- Visualize and scale a classic daily minimum temperature dataset\n",
    "- Convert the series into supervised sequences using a **sliding window**\n",
    "- Train an **LSTM regressor** with `EarlyStopping`\n",
    "- **Inverse-transform** predictions and compute **RMSE** on train/test sets\n",
    "- Compare results against a **feed-forward (MLP)** baseline\n",
    "\n",
    "> ðŸ’¡ **Tip:** Training is much faster on a GPU or Apple Silicon (MPS), but CPU works too.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIxJeXUxHNt3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "import keras\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPngd4VpKp59",
    "outputId": "bdeb7037-6fd7-4e54-9ed4-13d542b8f7de"
   },
   "outputs": [],
   "source": [
    "# Detect operating system and set Keras backend\n",
    "import platform\n",
    "import os\n",
    "system = platform.system()\n",
    "\n",
    "if system == \"Darwin\":  # macOS\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "    print(\"Detected macOS: Using TensorFlow backend\")\n",
    "else:  # Windows or Linux\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "    print(f\"Detected {system}: Using PyTorch backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcZlSeQQKq7r",
    "outputId": "fd249582-228a-4091-90a5-0d02264c8814"
   },
   "outputs": [],
   "source": [
    "# Check and configure device (GPU/CPU)\n",
    "def configure_device():\n",
    "    backend = os.environ.get(\"KERAS_BACKEND\", \"tensorflow\")\n",
    "\n",
    "    if backend == \"tensorflow\":\n",
    "        import tensorflow as tf\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            print(f\"GPU available: {len(gpus)} GPU(s) detected\")\n",
    "            print(f\"Using GPU: {gpus[0].name}\")\n",
    "            return \"GPU\"\n",
    "        else:\n",
    "            print(\"No GPU detected. Using CPU\")\n",
    "            return \"CPU\"\n",
    "\n",
    "    elif backend == \"torch\":\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "            print(\"Using GPU\")\n",
    "            return \"GPU\"\n",
    "        else:\n",
    "            print(\"No GPU detected. Using CPU\")\n",
    "            return \"CPU\"\n",
    "\n",
    "device_type = configure_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDc6yS63HNt5"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We start by loading the daily minimum temperature dataset, parsing the dates, and visualizing the overall trend. This helps us understand the time range and any patterns or anomalies in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygR-_az6HNt6"
   },
   "source": [
    "### Step 1 â€”  Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-01T16:48:36.641745Z",
     "iopub.status.busy": "2025-11-01T16:48:36.640996Z",
     "iopub.status.idle": "2025-11-01T16:48:36.661232Z",
     "shell.execute_reply": "2025-11-01T16:48:36.660481Z",
     "shell.execute_reply.started": "2025-11-01T16:48:36.641718Z"
    },
    "id": "eBkr9txcHNt6",
    "outputId": "6417968f-6bb6-48b7-8428-0e3d1f97d655",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "TEMPERATURES_CSV = 'daily-min-temperatures.csv'\n",
    "df = pd.read_csv(TEMPERATURES_CSV)\n",
    "# Parse and sort dates if available\n",
    "if 'Date' in df.columns:\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "print(f\"Dataframe shape: {df.shape}\")\n",
    "if 'Date' in df.columns:\n",
    "    print(f\"Date range: {df['Date'].min().date()} â†’ {df['Date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "AEsWkEnZHNt6",
    "outputId": "aaebdc60-3e9a-4040-b383-a221c48dc8fd"
   },
   "outputs": [],
   "source": [
    "# plot the trend, use the date as the x-axis\n",
    "df.plot(x='Date', y='Temp')\n",
    "# x-axis labels rotate 45 degrees\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8x-OCCFiHNt6"
   },
   "source": [
    "This is a univariate time series prediction problem: we use past values of the temperature to predict future values. This approach leverages the temporal dependencies in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnXN1nygHNt7"
   },
   "source": [
    "### Step 2 â€” Reshape the univariate series into a 2-D feature array\n",
    "\n",
    "In a univariate time-series, we have only one feature (e.g., temperature), so the raw data is a 1-D array.\n",
    "\n",
    "However, deep learning models (such as LSTMs, GRUs, and MLPs) expect input data to be at least 2-D or 3-D tensors, not plain 1-D vectors.\n",
    "\n",
    "Therefore, we reshape the series into a 2-D array with shape:\n",
    "\n",
    "**(samples, features)** = **(N, 1)**\n",
    "\n",
    "This prepares the data for sliding-window (sequence) creation and later reshaping to 3-D for LSTM input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKmpTL0zHNt7",
    "outputId": "c40e1d25-6a61-4f27-8968-6c66f6272524"
   },
   "outputs": [],
   "source": [
    "series = df['Temp'].values.astype(float).reshape(-1, 1)\n",
    "print(f\"Dataset shape: {series.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QL7Iy8IhHNt7"
   },
   "source": [
    "### Step 3 â€” Chronological split: train+val vs test\n",
    "\n",
    "You cannot use random way of splitting dataset into train and test as the sequence of events is important for time series.\n",
    "we will take first 80% values for train and the remaining 20 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BNMpcCBHNt7"
   },
   "outputs": [],
   "source": [
    "#set the ratios for test and validation\n",
    "TEST_RATIO = 0.125     # last 20% for test\n",
    "VAL_RATIO  = 0.125   # last 12.5% of (train+val) for val (â‰ˆ10% overall)\n",
    "\n",
    "# Chronological split: train+val vs test\n",
    "n_total = len(series)\n",
    "n_test  = int(np.round(TEST_RATIO * n_total))\n",
    "series_trainval = series[: n_total - n_test]   # no future leakage\n",
    "series_test     = series[n_total - n_test :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZL4MQ5YHNt7"
   },
   "outputs": [],
   "source": [
    "# Split train+val into train and val sets\n",
    "n_trainval = len(series_trainval)\n",
    "n_val_raw  = int(np.round(VAL_RATIO * n_trainval))\n",
    "n_train_raw = n_trainval - n_val_raw\n",
    "\n",
    "series_train_raw = series_trainval[:n_train_raw]\n",
    "series_val_raw   = series_trainval[n_train_raw:]\n",
    "series_test_raw  = series_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bNIaiNVHNt7"
   },
   "source": [
    "### Step 4 - Feature Scaling\n",
    "\n",
    "LSTMs are sensitive to the scale of input data. We normalize the series (e.g., to [0, 1]) before training to ensure stable and efficient learning.\n",
    "\n",
    "**Note:**\n",
    "- In production, always fit the scaler on the training set only to avoid data leakage. Here, for simplicity, we fit on the full series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "K0AFyX6SHNt7",
    "outputId": "1a37b7f2-09d8-4fc4-9da3-a01e2eaa112b"
   },
   "outputs": [],
   "source": [
    "# Fit scaler ONLY on training raw values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(series_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Crb-UolYHNt7"
   },
   "outputs": [],
   "source": [
    "# Transform each split separately\n",
    "train_scaled = scaler.transform(series_train_raw)\n",
    "val_scaled   = scaler.transform(series_val_raw)\n",
    "test_scaled  = scaler.transform(series_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPSWpnAkHNt8"
   },
   "source": [
    "\n",
    "### Step 5 â€” Transform the Time Series into a Supervised Learning Format\n",
    "\n",
    "To train a LSTM model on sequences, we convert the time series into **inputâ€“output pairs** using a sliding window.  \n",
    "Each input window contains a fixed number of **past observations**, and the corresponding target is the **next value** in the series.\n",
    "\n",
    "This turns our time-series data into a supervised learning problem suitable for LSTM\n",
    "\n",
    "LSTM models require data in the format: (samples, time_steps, features)\n",
    "\n",
    "<img src=\"https://www.mdpi.com/applsci/applsci-13-04644/article_deploy/html/images/applsci-13-04644-g002.png\" alt=\"Sliding window example\" width=\"600\" height=\"400\">\n",
    "\n",
    "\n",
    "The function below generates these input/output sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0EExk3sHNt8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# helper function\n",
    "def make_windows(series_2d, window=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series_2d) - window):\n",
    "        X.append(series_2d[i:i+window, :])   # (window, 1)\n",
    "        y.append(series_2d[i+window, :])     # (1,)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkiEXzIvHNt8"
   },
   "source": [
    "So after creating the sliding windows, we reshape the training and validation sets into this 3-D structure and print their shapes to confirm everything is aligned correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uUFlhMGHNt8",
    "outputId": "5ec5a3dc-bda2-400f-d275-761ced2d2054"
   },
   "outputs": [],
   "source": [
    "WINDOW = 7  # days of historical data to use for prediction\n",
    "# Build windows for each split independently (no cross-split mixing)\n",
    "train_X, train_y = make_windows(train_scaled, WINDOW)\n",
    "val_X,   val_y   = make_windows(val_scaled,   WINDOW)\n",
    "test_X,  test_y  = make_windows(test_scaled,  WINDOW)\n",
    "\n",
    "print(f\"train_X: {train_X.shape}, train_y: {train_y.shape}\")\n",
    "print(f\"val_X:   {val_X.shape},   val_y:   {val_y.shape}\")\n",
    "print(f\"test_X:  {test_X.shape},  test_y:  {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is ready, let's build your models next!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imO4YALeHNt8"
   },
   "source": [
    "## Time Series Forcasting\n",
    "\n",
    "### Task 1: Build your LSTM Model for time series\n",
    "\n",
    "Construct a simple LSTM model with two layers:\n",
    "\n",
    "- LSTM layer with 50 units\n",
    "- Dense output layer with 1 unit (for regression)\n",
    "\n",
    "Use the Adam optimizer and mean squared error loss to compile the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "Zbdaqe1_HNt8",
    "outputId": "af17bdfa-e55f-4772-aadc-bcb143cb999a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# build the LSTM model\n",
    "\n",
    "\n",
    "# compile the model\n",
    "\n",
    "\n",
    "# display the model summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E45z_zIuHNt8"
   },
   "source": [
    "### Task 2: Train Your LSTM with Early Stopping\n",
    "\n",
    "Now train your LSTM model using the following configuration:\n",
    "\n",
    "**Early Stopping Callback:**\n",
    "- Monitor: `val_loss` (validation loss)\n",
    "- Patience: `5` epochs (stop if no improvement for 5 consecutive epochs)\n",
    "- Restore best weights: `True` (automatically load the weights from the epoch with the best validation loss)\n",
    "\n",
    "**Training Configuration:**\n",
    "- Training data: `train_X`, `train_y`\n",
    "- Validation data: `val_X`, `val_y` (use the `validation_data` parameter)\n",
    "- Epochs: `100` (maximum, but early stopping may end training sooner)\n",
    "- Batch size: `32`\n",
    "- Shuffle: `False` (important for time series to preserve temporal order)\n",
    "- Verbose: `1` (display progress)\n",
    "- Callbacks: `[early_stopping]`\n",
    "\n",
    "**Why Early Stopping?**\n",
    "\n",
    "Early stopping prevents overfitting by monitoring the validation loss. If the model stops improving on the validation set, training halts and the best weights are restored. This saves time and ensures you get the best-performing model without manual tuning.\n",
    "\n",
    "The code below is already set up the structure for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-01T16:48:43.460613Z",
     "iopub.status.busy": "2025-11-01T16:48:43.460405Z",
     "iopub.status.idle": "2025-11-01T16:48:49.681918Z",
     "shell.execute_reply": "2025-11-01T16:48:49.681179Z",
     "shell.execute_reply.started": "2025-11-01T16:48:43.460590Z"
    },
    "id": "GsdV-vfRHNt8",
    "outputId": "b5591b5c-a66b-4711-89c6-f0e68a497bb8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "\n",
    "\n",
    "# Train the LSTM model with early stopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYe-tmgVHNt8"
   },
   "source": [
    "### Task 3: Plotting the training and validation loss below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "execution": {
     "iopub.execute_input": "2025-11-01T16:48:49.683411Z",
     "iopub.status.busy": "2025-11-01T16:48:49.682885Z",
     "iopub.status.idle": "2025-11-01T16:48:49.826880Z",
     "shell.execute_reply": "2025-11-01T16:48:49.826056Z",
     "shell.execute_reply.started": "2025-11-01T16:48:49.683389Z"
    },
    "id": "PXEZtHM1HNt8",
    "outputId": "21922ff3-0d1c-4184-f135-25c7e1274200",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plot the training and validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "for6w_5mHNt8"
   },
   "source": [
    "### Task 4: Generate Predictions and Evaluate Performance\n",
    "\n",
    "Now that your LSTM model is trained, it's time to:\n",
    "\n",
    "1. **Generate predictions** on all three datasets (train, validation, test)\n",
    "2. **Inverse-transform** the predictions back to the original temperature scale\n",
    "3. **Compute evaluation metrics** (RMSE and MAE) to assess model performance\n",
    "\n",
    "**What you need to do:**\n",
    "\n",
    "**Step 1: Generate Predictions (Scaled)**\n",
    "- Use `lstm_model.predict()` to generate predictions for `train_X`, `val_X`, and `test_X`\n",
    "- Store the results in `train_pred`, `val_pred`, and `test_pred`\n",
    "\n",
    "**Step 2: Inverse-Transform to Original Scale**\n",
    "- Remember: Your data was normalized using `MinMaxScaler`\n",
    "- Use `scaler.inverse_transform()` to convert predictions back to original temperature units\n",
    "- Also inverse-transform the actual target values (`train_y`, `val_y`, `test_y`)\n",
    "- Store the inverse-transformed predictions in `train_pred_inv`, `val_pred_inv`, `test_pred_inv`\n",
    "- Store the inverse-transformed targets in `train_y_inv`, `val_y_inv`, `test_y_inv`\n",
    "\n",
    "**Step 3: Calculate Performance Metrics**\n",
    "- Compute **RMSE** (Root Mean Squared Error) using `root_mean_squared_error()`\n",
    "- Compute **MAE** (Mean Absolute Error) using `mean_absolute_error()`\n",
    "- Print the metrics for all three datasets (train, validation, test)\n",
    "\n",
    "**Why inverse-transform?**\n",
    "- Predictions are in the [0, 1] normalized range\n",
    "- Inverse-transforming converts them back to degrees Celsius\n",
    "- This makes the error metrics interpretable (e.g., RMSE of 2.5Â°C is meaningful)\n",
    "\n",
    "\n",
    "The code structure is provided below â€” complete the missing parts!\n",
    "Please use the **same variable names** shown in the next section so your predictions can be visualized correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lsOCtjOXHNt9",
    "outputId": "0d0909ff-f1df-441c-f3a0-bbb5e42f0566"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Making prediction\n",
    "\n",
    "\n",
    "# Inverse-transform back to original units\n",
    "\n",
    "\n",
    "# Evaluate the model performance\n",
    "\n",
    "\n",
    "# Print RMSE and MAE for each split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "Train RMSE: X.XXX,  MAE: X.XXX\n",
    "Val   RMSE: X.XXX,  MAE: X.XXX\n",
    "Test  RMSE: X.XXX,  MAE: X.XXX\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tJXkJwLHNt9"
   },
   "source": [
    "### Visualize Predictions\n",
    "\n",
    "We plot the original data along with the model's predictions for both the training and test sets. This visualization helps us see how closely the model tracks the actual temperature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "_IEYmfTAHNt9",
    "outputId": "c013b65e-9cfe-4cfc-cf9b-3a46e1f05e6d"
   },
   "outputs": [],
   "source": [
    "T = len(series)\n",
    "\n",
    "# Containers for aligned predictions (original units)\n",
    "train_pred_plot = np.full((T, 1), np.nan, dtype=float)\n",
    "val_pred_plot   = np.full((T, 1), np.nan, dtype=float)\n",
    "test_pred_plot  = np.full((T, 1), np.nan, dtype=float)\n",
    "\n",
    "# --- Train segment ---\n",
    "# train windows start at indices [0 .. n_train_raw-1] -> first pred aligns at index WINDOW\n",
    "train_start_idx = WINDOW\n",
    "train_end_idx   = train_start_idx + len(train_pred_inv)\n",
    "train_end_idx   = min(train_end_idx, n_train_raw)  # safety clip\n",
    "train_pred_plot[train_start_idx:train_end_idx, 0] = train_pred_inv[:(train_end_idx - train_start_idx), 0]\n",
    "\n",
    "# --- Validation segment ---\n",
    "# val segment starts at n_train_raw; first val pred aligns at n_train_raw + WINDOW\n",
    "val_seg_start   = n_train_raw\n",
    "val_start_idx   = val_seg_start + WINDOW\n",
    "val_end_idx     = val_start_idx + len(val_pred_inv)\n",
    "val_end_idx     = min(val_end_idx, n_trainval)  # validation ends at n_trainval\n",
    "val_pred_plot[val_start_idx:val_end_idx, 0] = val_pred_inv[:(val_end_idx - val_start_idx), 0]\n",
    "\n",
    "# --- Test segment ---\n",
    "# test segment starts at n_trainval; first test pred aligns at n_trainval + WINDOW\n",
    "test_seg_start  = n_trainval\n",
    "test_start_idx  = test_seg_start + WINDOW\n",
    "test_end_idx    = test_start_idx + len(test_pred_inv)\n",
    "test_end_idx    = min(test_end_idx, T)  # clip to total length\n",
    "test_pred_plot[test_start_idx:test_end_idx, 0] = test_pred_inv[:(test_end_idx - test_start_idx), 0]\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(series, label='Data')  # already in original units\n",
    "plt.plot(train_pred_plot, label='Train Predictions')\n",
    "plt.plot(val_pred_plot,   label='Validation Predictions')\n",
    "plt.plot(test_pred_plot,  label='Test Predictions')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Aligned Predictions vs Original Series')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Temperature')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUibHR2RHNt9"
   },
   "source": [
    "### Feed-Forward Neural Network (MLP) for Time Series\n",
    "\n",
    "Feed-forward neural networks (MLPs) can also be used for time series forecasting by flattening the input sequences. While they do not capture temporal dependencies as effectively as LSTMs, they are simple and efficient for many tasks.\n",
    "\n",
    "![](images/mlp_ts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jK8YrPFDHNt9"
   },
   "source": [
    "### Task 5: Data Preprocessing for MLP\n",
    "\n",
    "For MLPs, we flatten each input sequence so that each sample is a single vector. This allows the feed-forward network to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-01T16:51:53.091110Z",
     "iopub.status.busy": "2025-11-01T16:51:53.090490Z",
     "iopub.status.idle": "2025-11-01T16:51:53.095242Z",
     "shell.execute_reply": "2025-11-01T16:51:53.094286Z",
     "shell.execute_reply.started": "2025-11-01T16:51:53.091087Z"
    },
    "id": "ARS36uE_HNt9",
    "outputId": "aec11238-432a-49be-f71d-2141d8381d62",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Flatten sliding window for MLP:\n",
    "# (samples, timesteps, features) -> (samples, timesteps*features)\n",
    "\n",
    "\n",
    "print(\"MLP shapes:\", train_X_mlp.shape, val_X_mlp.shape, test_X_mlp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPkAcpdqHNt9"
   },
   "source": [
    "### Task 6: Build the MLP Model\n",
    "\n",
    "Now let's build a **feed-forward neural network (MLP)** to compare against the LSTM's performance.\n",
    "\n",
    "**Your Task:**\n",
    "Construct a simple MLP with the following architecture:\n",
    "\n",
    "**Model Structure:**\n",
    "1. **Input Layer:**\n",
    "   - Use `Input(shape=...)` to define the input\n",
    "\n",
    "2. **First Hidden Layer:**\n",
    "   - 100 units (neurons)\n",
    "   - Activation function: `'relu'` (Rectified Linear Unit)\n",
    "\n",
    "3. **Second Hidden Layer:**\n",
    "   - 32 units\n",
    "   - Activation function: `'relu'`\n",
    "\n",
    "4. **Output Layer:**\n",
    "   - 1 unit (single temperature value prediction)\n",
    "   - No activation (linear activation for regression)\n",
    "\n",
    "**Compilation:**\n",
    "- Optimizer: `'adam'`\n",
    "- Loss function: `'mse'` (mean squared error, same as LSTM)\n",
    "\n",
    "\n",
    "The code structure is already provided below â€” just fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "execution": {
     "iopub.execute_input": "2025-11-01T16:51:55.748007Z",
     "iopub.status.busy": "2025-11-01T16:51:55.747723Z",
     "iopub.status.idle": "2025-11-01T16:51:55.799084Z",
     "shell.execute_reply": "2025-11-01T16:51:55.798490Z",
     "shell.execute_reply.started": "2025-11-01T16:51:55.747987Z"
    },
    "id": "rbkELXNwHNt_",
    "outputId": "75b4d5a2-7b59-4005-8946-fd915b750110",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Build MLP ---\n",
    "\n",
    "\n",
    "# Compile the MLP model\n",
    "\n",
    "\n",
    "# model summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bmqIH9fHNt_"
   },
   "source": [
    "### Task 7: Train, Evaluate, and Visualize the MLP\n",
    "\n",
    "Train your MLP with the same setup as the LSTM, make predictions, report RMSE/MAE, and visualize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-01T16:52:00.823828Z",
     "iopub.status.busy": "2025-11-01T16:52:00.823263Z",
     "iopub.status.idle": "2025-11-01T16:52:04.622908Z",
     "shell.execute_reply": "2025-11-01T16:52:04.622360Z",
     "shell.execute_reply.started": "2025-11-01T16:52:00.823805Z"
    },
    "id": "UhzO5FpYHNuD",
    "outputId": "0f414cb9-97e5-473e-b794-5356a1e69350",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Train MLP ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-01T16:53:45.403305Z",
     "iopub.status.busy": "2025-11-01T16:53:45.402768Z",
     "iopub.status.idle": "2025-11-01T16:53:45.736324Z",
     "shell.execute_reply": "2025-11-01T16:53:45.735536Z",
     "shell.execute_reply.started": "2025-11-01T16:53:45.403282Z"
    },
    "id": "UxbVHw9rHNuD",
    "outputId": "ad737899-1fc6-416b-bf4f-a007a7f6c48d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Predictions ---\n",
    "\n",
    "\n",
    "# inverse transform\n",
    "\n",
    "# print out the performance in terms of rmse and mae"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8626891,
     "sourceId": 13579157,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6571792,
     "sourceId": 10614940,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
