{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e11411",
   "metadata": {},
   "source": [
    "# Keras with the PyTorch Backend: MNIST CNN Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5fef52",
   "metadata": {},
   "source": [
    "This walkthrough prepares you to build and train neural networks with Keras while running on the PyTorch backend. We'll mirror the tooling students will use on quizzes and homework: the Sequential API, common layers, compilation settings, callbacks, evaluation, predictions, and saving models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee941e",
   "metadata": {},
   "source": [
    " # Video walkthrough:\n",
    " https://northwestern.zoom.us/rec/share/iNJ--cLUYj22vPyCpKEVZalP11wzQzJ63g8RbXLjYAp-P5M9919yG-907RDaA8sT.0DN2MWY7gmjwIoBg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94492138",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "- Configure Keras to run with the PyTorch backend\n",
    "- Load and preprocess image data\n",
    "- Build convolutional models with the Sequential API\n",
    "- Compile models with the right losses, optimizers, and metrics\n",
    "- Train with validation data and interpret history plots\n",
    "- Evaluate, predict, and persist models for later reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive summary\n",
    "\n",
    "- Connect Keras 3 to the PyTorch runtime so you can reuse PyTorch tooling while staying in the high-level Keras API.\n",
    "- Walk through an end-to-end MNIST pipeline: inspect raw digits, normalize the data, and add the channel dimension PyTorch convolutions expect.\n",
    "- Assemble and train a compact Sequential CNN while monitoring the metrics that appear on quizzes (loss, accuracy, early stopping).\n",
    "- Capture best-performing weights with callbacks, evaluate on held-out data, and generate sample predictions to sanity-check the model.\n",
    "- Stretch toward project work with a Functional API variant and guided experiments in the sandbox cells provided at the end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01195c72",
   "metadata": {},
   "source": [
    "## 0. Prerequisites\n",
    "\n",
    "Make sure your environment has the PyTorch backend enabled for Keras 3. If you are working locally and `torch` is missing, install the `[torch]` extra for Keras (replace the index URL with the right one for your platform):\n",
    "\n",
    "```bash\n",
    "pip install 'keras[torch]' torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "```\n",
    "\n",
    "After installation, start a **fresh kernel** and run the snippet below once to switch and confirm the backend before importing heavy submodules (like `keras.layers`):\n",
    "\n",
    "```python\n",
    "import keras\n",
    "keras.config.set_backend(\"torch\")\n",
    "print(\"Using backend:\", keras.config.backend())\n",
    "```\n",
    "\n",
    "If you have access to a GPU, install the matching CUDA wheel from [pytorch.org/get-started](https://pytorch.org/get-started/locally/) and the backend call above will automatically pick it up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b9cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import ops\n",
    "\n",
    "# Switch to the PyTorch backend if the environment is still on TensorFlow.\n",
    "if keras.config.backend() != 'torch':\n",
    "    keras.config.set_backend('torch')\n",
    "\n",
    "import torch\n",
    "print('Keras version:', keras.__version__)\n",
    "print('Selected backend:', keras.config.backend())\n",
    "print('PyTorch version:', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "Keras 3 can talk to multiple numerical runtimes. Explicitly switching to the PyTorch backend up front guarantees the rest of the notebook exercises the same kernels, memory formats, and GPU support that students use in other PyTorch-heavy assignments. If you forget this step, you risk silently training with TensorFlow and getting different performance characteristics or API behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca978cd5",
   "metadata": {},
   "source": [
    "> **Tip:** If the backend still prints `tensorflow`, restart the notebook runtime after installing PyTorch and rerun the config cell. You can call `keras.config.list_backends()` to view the valid options and confirm that `torch` is available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8565493b",
   "metadata": {},
   "source": [
    "## 1. Load and inspect the MNIST dataset\n",
    "\n",
    "We'll classify handwritten digits. Keras ships the dataset so we do not need external downloads. Each image is a 28×28 grayscale grid, and the labels range from 0–9. Expect 60,000 training samples and 10,000 test samples—perfect for quick iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d68d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('Training set shape:', x_train.shape, y_train.shape)\n",
    "print('Test set shape:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "Inspecting the raw shapes before any preprocessing catches issues such as truncated downloads or swapped axes. MNIST’s balanced class distribution also makes it the perfect sandbox: success criteria are clear, and students can translate the workflow to harder datasets later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8fd0f4",
   "metadata": {},
   "source": [
    "### Normalize and add a channel dimension\n",
    "\n",
    "PyTorch convolutions expect a channel axis. We scale pixel intensities into [0, 1] floats and append a singleton channel dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ff9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert uint8 images to float32 [0, 1]\n",
    "x_train = (x_train.astype('float32') / 255.0)[..., None]\n",
    "x_test = (x_test.astype('float32') / 255.0)[..., None]\n",
    "\n",
    "print('Updated shape:', x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "Normalizing pixel values stabilizes gradients so optimizers converge faster, and adding the channel dimension aligns the data with PyTorch’s `NCHW` expectation. Skipping either step leads to training instability or shape errors downstream.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252b6d9",
   "metadata": {},
   "source": [
    "### Peek at a few digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa782267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "for i in range(8):\n",
    "    plt.subplot(1, 8, i + 1)\n",
    "    plt.imshow(x_train[i, ..., 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(int(y_train[i]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "Visual checks expose label mismatches, corrupted samples, or preprocessing bugs long before you commit to a full training run. Investing ten seconds here saves minutes of debugging later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructor checklist\n",
    "\n",
    "- Confirm the plotted digits match the labels printed on top of each subplot.\n",
    "- Watch for inverted colors or noisy pixels—signs that normalization or reshaping went wrong.\n",
    "- Encourage students to swap `i` in the loop to explore more samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863af44",
   "metadata": {},
   "source": [
    "## 2. Build a Sequential CNN\n",
    "\n",
    "We start with a compact convolutional architecture tailored to MNIST. Two convolution–pooling blocks learn local stroke patterns, followed by dropout-regularized dense layers that map features to digit probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(pool_size=2),\n",
    "    layers.Conv2D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "Reading the model summary connects abstract architecture diagrams to concrete tensor shapes. Students learn how pooling shrinks spatial dimensions, why dropout reduces overfitting, and how many parameters they are responsible for training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d9f990",
   "metadata": {},
   "source": [
    "Key layers you should recognize for quizzes/homework:\n",
    "- `Conv2D`: learnable filters capturing local patterns\n",
    "- `MaxPooling2D`: downsample feature maps\n",
    "- `Dropout`: regularization to fight overfitting\n",
    "- `Dense` with `softmax`: map to class probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26bd531",
   "metadata": {},
   "source": [
    "## 3. Compile the model\n",
    "\n",
    "We use Adam, categorical cross-entropy, and accuracy—exactly the training stack students will rely on. Adjust the learning rate if you see plateaus or diverging loss in later experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy(name='accuracy')],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "Adam with categorical cross-entropy is the baseline trio our assessments expect. Understanding the defaults lets students reason about when to adjust learning rates, swap optimizers, or track additional metrics for research questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35acd6",
   "metadata": {},
   "source": [
    "## 4. Prepare labels and callbacks\n",
    "\n",
    "Convert labels to one-hot vectors for the softmax output layer and configure callbacks that align with homework expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf683a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "y_train_categorical = to_categorical(y_train, num_classes=10)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint('mnist_cnn_torch.keras', save_best_only=True),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "One-hot labels unlock the softmax output, and callbacks enforce reproducibility. Early stopping prevents wasted epochs once validation loss plateaus, while checkpointing preserves the best weights for reports or deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b96fd2",
   "metadata": {},
   "source": [
    "`EarlyStopping` mirrors what we encourage in assignments: stop once validation loss stops improving for a few epochs. `ModelCheckpoint` persists your best weights automatically, giving you a fallback if later epochs overfit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8803b5ff",
   "metadata": {},
   "source": [
    "## 5. Train with validation data\n",
    "\n",
    "Keep an eye on the history dictionary—it will show up on quizzes. With the settings below, you should see ~99% validation accuracy in under a minute on modern hardware.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b0f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train_categorical,\n",
    "    epochs=15,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "The training loop is where theory meets hardware constraints. By logging history on every epoch, students can tie optimizer choices to observable behavior—critical when justifying design decisions on homework and exams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the training logs\n",
    "\n",
    "- Look for validation loss to flatten or rise slightly—that is when `EarlyStopping` will trigger.\n",
    "- If training accuracy climbs while validation accuracy stagnates, consider more dropout or data augmentation.\n",
    "- Large gaps between training and validation loss often signal overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad658c15",
   "metadata": {},
   "source": [
    "### Plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dbd0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Curves')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Curves')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the curves\n",
    "\n",
    "- Balanced, downward loss curves for both splits indicate the optimizer is behaving.\n",
    "- Validation accuracy should track training accuracy; a large gap suggests the model is memorizing.\n",
    "- Screenshot these plots for lab reports—they double as evidence of convergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "Turning raw history values into visual diagnostics helps students develop intuition. Patterns like widening loss gaps or noisy accuracy swings become immediate cues to tweak architecture or regularization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa79adf6",
   "metadata": {},
   "source": [
    "## 6. Evaluate on the test set\n",
    "\n",
    "Hold back the official test split until now so you get an unbiased estimate of generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dafc488",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test_categorical, verbose=0)\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "Holding the test split until the end preserves an honest estimate of generalization. Reporting both loss and accuracy reinforces that metrics can tell complementary stories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6f2c71",
   "metadata": {},
   "source": [
    "## 7. Make predictions\n",
    "\n",
    "Grab a handful of samples and inspect both the predicted labels and the raw probability vectors. This quick sanity check catches label shuffling mistakes early.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict(x_test[:5])\n",
    "predicted_digits = np.argmax(probabilities, axis=1)\n",
    "\n",
    "for i, (pred, target) in enumerate(zip(predicted_digits, y_test[:5])):\n",
    "    print(f'Sample {i}: predicted {pred}, target {target}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "Checking a handful of predictions humanizes the model’s behavior. Students practice spotting when high-confidence errors stem from ambiguous data, preprocessing mistakes, or insufficient model capacity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity checks\n",
    "\n",
    "- Confirm the predicted digit matches the target for most samples.\n",
    "- Investigate any confident misclassifications—were the inputs ambiguous or noisy?\n",
    "- Consider displaying `probabilities[i]` to discuss softmax confidence calibration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cf9bf",
   "metadata": {},
   "source": [
    "## 8. Reload the best model from disk\n",
    "\n",
    "`ModelCheckpoint` saved a `.keras` file. Reload it to demonstrate how we recover the best-performing weights for deployment or further evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model('mnist_cnn_torch.keras')\n",
    "reloaded_loss, reloaded_accuracy = best_model.evaluate(x_test, y_test_categorical, verbose=0)\n",
    "print(f'Reloaded model accuracy: {reloaded_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "Being able to reload and evaluate saved weights is essential for collaboration, grading, and deployment. It proves the training artifacts are portable across sessions and machines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4cfcd",
   "metadata": {},
   "source": [
    "## 9. Optional: Functional API example\n",
    "\n",
    "For more complex homeworks, you may need skip connections or parallel branches. Here is the same classifier built with the Functional API so you can practice moving between paradigms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e59b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "functional_model = keras.Model(inputs, outputs, name='mnist_functional')\n",
    "functional_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this matters\n",
    "\n",
    "The Functional API is the bridge to advanced architectures. Understanding it now means students can later implement residual blocks, attention mechanisms, or multi-branch models without switching frameworks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fa253",
   "metadata": {},
   "source": [
    "Compile, train, and evaluate this model with the same pipeline as practice. The Functional API becomes essential for architectures like residual blocks or multi-input models—skills you'll tap during the final project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a143aa0",
   "metadata": {},
   "source": [
    "## 10. Your turn\n",
    "\n",
    "Use the empty cells below to experiment. Tie your notes back to the lab rubric by capturing metrics, plots, and a 2–3 sentence reflection for each tweak you try.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36c7b2",
   "metadata": {},
   "source": [
    "### Task A: Try a different optimizer (e.g., RMSprop) and compare the learning curves.\n",
    "\n",
    "Focus on how quickly each optimizer reaches 98% validation accuracy and whether the loss curves stay smooth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeea859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40a8240d",
   "metadata": {},
   "source": [
    "### Task B: Add Batch Normalization after each convolution and observe its impact.\n",
    "\n",
    "Record convergence speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0997ee29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03fcd5a8",
   "metadata": {},
   "source": [
    "### Task C: Build a deeper network (3+ convolutional blocks) and monitor for overfitting.\n",
    "\n",
    "Track validation loss and test accuracy; try pairing additional depth with stronger regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf505d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
