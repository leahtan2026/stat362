{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "id": "vTZLHktLDHUB",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "title: \"HW2_1: Image Classification using CNN with/without Data Augmentation\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-title: Contents\n",
        "    toc-depth: 4\n",
        "    code-fold: show\n",
        "    self-contained: true\n",
        "jupyter: python3\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4C3qscsDHUC"
      },
      "source": [
        "![](../images/data_augmentation.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZHD0EVmDHUC"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this notebook, you'll tackle **image classification** using **Convolutional Neural Networks (CNNs)**. As demonstrated in lectures, there's a fundamental principle in deep learning: **deeper networks typically possess greater model capacity**. However, this increased capacity often leads to a higher risk of **overfitting**, as the number of learnable parameters escalates significantly.\n",
        "\n",
        "### The Role of Data Augmentation\n",
        "\n",
        "In CNNs, **Data Augmentation** emerges as a crucial technique to bolster the model's robustness against overfitting. By applying transformations such as:\n",
        "\n",
        "- **Rotation** (random angles)\n",
        "- **Shifting** (horizontal and vertical translation)\n",
        "- **Flipping** (horizontal/vertical mirroring)\n",
        "- **Zooming** (scaling in/out)\n",
        "- **Shearing** (slanting transformations)\n",
        "\n",
        "Data Augmentation artificially **diversifies the training dataset**, helping the model generalize better to unseen data. Widely embraced since its introduction in **AlexNet (2012)**, Data Augmentation has become a cornerstone technique in modern computer vision.\n",
        "\n",
        "### About ImageDataGenerator\n",
        "\n",
        "`ImageDataGenerator` is a powerful utility class within the Keras library, facilitating:\n",
        "- **Image preprocessing** (rescaling, normalization)\n",
        "- **Real-time data augmentation** during model training\n",
        "- **Efficient batch loading** from disk\n",
        "\n",
        "It's primarily employed in tasks like image classification, object detection, and image segmentation.\n",
        "\n",
        "**Directory Structure Requirements:**\n",
        "\n",
        "To leverage `ImageDataGenerator` effectively, organize your image data into separate directories, each representing a distinct class:\n",
        "\n",
        "![Directory Structure](https://expoundai.files.wordpress.com/2019/04/directorystructure.png)\n",
        "\n",
        "### What You'll Do\n",
        "\n",
        "In this assignment, you'll:\n",
        "\n",
        "1. **Build a CNN with data augmentation** and evaluate its performance\n",
        "2. **Train the same model WITHOUT augmentation** to observe overfitting\n",
        "\n",
        "This comparison will clearly illustrate the effectiveness of data augmentation in mitigating overfitting.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYqidndGDHUD"
      },
      "source": [
        "## Setup: Import Required Libraries\n",
        "\n",
        "First, import the necessary libraries for image processing, model building, and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTrI4hqoDHUD",
        "outputId": "cf4e9f3b-bd8e-4eee-bc56-76897f7e515e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'torch'\n",
        "\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(f\"Keras version: {keras.__version__}\")\n",
        "print(f\"Using backend: {keras.backend.backend()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln__nsfXDHUE"
      },
      "source": [
        "### Check Device Availability\n",
        "\n",
        "Let's verify whether GPU acceleration is available for faster training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMvRrh-yDHUE",
        "outputId": "82f26dd6-c6e6-45fe-e556-74564f2a6d90"
      },
      "outputs": [],
      "source": [
        "# Check for GPU availability\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"✓ GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(\"  Training will be significantly faster on GPU!\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"⚠ No GPU detected - using CPU\")\n",
        "    print(\"  Training will be slower. Consider using Google Colab or Kaggle Kernel for free GPU access.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-KvWdEqDHUE"
      },
      "source": [
        "## Step 1: Load the 10-Flowers Dataset\n",
        "\n",
        "Load the dataset, which contains images of **10 different flower species** organized into subfolders. Each subfolder represents a different flower class (labeled 0-9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFbiyWFBDHUE"
      },
      "outputs": [],
      "source": [
        "\n",
        "local_zip = '10flows.zip'\n",
        "\n",
        "if not os.path.exists(local_zip):\n",
        "    print(\"Please copy the 10flows.zip file to the current directory\")\n",
        "else:\n",
        "    zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('.')\n",
        "    zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH4coAmbDHUE"
      },
      "source": [
        "### Dataset Overview\n",
        "\n",
        "Let's examine the **class distribution** — the number of images for each flower class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q620YTX2DHUE",
        "outputId": "28f0a743-25b1-4e3b-9f49-c8b0c69489ec"
      },
      "outputs": [],
      "source": [
        "source_path = 'flowers'\n",
        "\n",
        "for label in range(10):\n",
        "    print(f\"There are {len(os.listdir(os.path.join(source_path, str(label))))} images of {label}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELnkioNNDHUF"
      },
      "source": [
        "### Visual Exploration\n",
        "\n",
        "Display **5 random sample images** from each of the 10 flower classes to get a sense of the dataset's diversity:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "FNRnRlTsDHUF",
        "outputId": "09f292d2-3966-4ad5-a899-f41d839a2375"
      },
      "outputs": [],
      "source": [
        "# show 5 random images from each class in a 10x5 grid\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i in range(10):\n",
        "    for j in range(5):\n",
        "        img = plt.imread(f'flowers/{i}/{random.choice(os.listdir(f\"flowers/{i}\"))}')\n",
        "        fig.add_subplot(10, 5, i*5+j+1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TStRumW9DHUF",
        "outputId": "ca5078b6-694c-4714-c34f-b8daa1616f73"
      },
      "outputs": [],
      "source": [
        "# print out the size of each image\n",
        "img = plt.imread(f'flowers/0/{random.choice(os.listdir(\"flowers/0\"))}')\n",
        "print(f\"Image size: {img.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEDZf0QYDHUF"
      },
      "source": [
        "## Step 2: Split Dataset into Training, Validation, and Test Sets\n",
        "\n",
        "We'll organize the data into a directory structure compatible with Keras' `ImageDataGenerator`.\n",
        "\n",
        "**Split Ratios:**\n",
        "- **Training**: 70% (for learning patterns)\n",
        "- **Validation**: 20% (for hyperparameter tuning and monitoring)\n",
        "- **Test**: 10% (for final evaluation)\n",
        "\n",
        "You don't need to modify anything in this step — just run the code to create the proper directory structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMDgB0V6DHUF"
      },
      "outputs": [],
      "source": [
        "# Define root directory\n",
        "root_dir = 'sandbox'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "def create_train_val_dirs(root_path):\n",
        "  \"\"\"\n",
        "  Creates directories for the train and test sets\n",
        "\n",
        "  Args:\n",
        "    root_path (string) - the base directory path to create subdirectories from\n",
        "\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  for name in range(10):\n",
        "    for name2 in ['training','validation','test']:\n",
        "      os.makedirs(os.path.join(root_path,name2,str(name)))\n",
        "\n",
        "try:\n",
        "  create_train_val_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx-OmeesDHUF",
        "outputId": "a055b722-7065-4641-8681-61628c28db33"
      },
      "outputs": [],
      "source": [
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbJ6mTCcDHUF"
      },
      "outputs": [],
      "source": [
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, TEST_DIR, TRAIN_SPLIT, VAL_SPLIT):\n",
        "    \"\"\"\n",
        "    Splits the data into train, validation, and test sets.\n",
        "\n",
        "    Args:\n",
        "        SOURCE_DIR (string): directory path containing the images\n",
        "        TRAINING_DIR (string): directory path to be used for training\n",
        "        VALIDATION_DIR (string): directory path to be used for validation\n",
        "        TEST_DIR (string): directory path to be used for testing\n",
        "        TRAIN_SPLIT (float): proportion of the dataset to be used for training\n",
        "        VAL_SPLIT (float): proportion of the dataset to be used for validation\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(42)\n",
        "    files = []\n",
        "    for name in os.listdir(SOURCE_DIR):\n",
        "        if os.path.getsize(os.path.join(SOURCE_DIR, name)) > 0:\n",
        "            files.append(name)\n",
        "    random.shuffle(files)\n",
        "\n",
        "    train_size = int(len(files) * TRAIN_SPLIT)\n",
        "    val_size = int(len(files) * VAL_SPLIT)\n",
        "\n",
        "    for name in files[:train_size]:\n",
        "        shutil.copy(os.path.join(SOURCE_DIR, name), os.path.join(TRAINING_DIR, name))\n",
        "    for name in files[train_size:train_size + val_size]:\n",
        "        shutil.copy(os.path.join(SOURCE_DIR, name), os.path.join(VALIDATION_DIR, name))\n",
        "    for name in files[train_size + val_size:]:\n",
        "        shutil.copy(os.path.join(SOURCE_DIR, name), os.path.join(TEST_DIR, name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU-RcWjlDHUF"
      },
      "source": [
        "### Execute the Data Split\n",
        "\n",
        "Run the cell below to split the dataset and verify the distribution across training, validation, and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90pYQkOdDHUF",
        "outputId": "56bfb114-abc5-4ce5-f704-ee1afaa45454"
      },
      "outputs": [],
      "source": [
        "TRAINING_DIR = \"sandbox/training/\"\n",
        "VALIDATION_DIR = \"sandbox/validation/\"\n",
        "TEST_DIR = \"sandbox/test/\"\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "for i in range(10):\n",
        "  label_train_dir = os.path.join(TRAINING_DIR, str(i))\n",
        "  label_val_dir = os.path.join(VALIDATION_DIR, str(i))\n",
        "  label_test_dir = os.path.join(TEST_DIR, str(i))\n",
        "  if len(os.listdir(label_train_dir)) > 0:\n",
        "    for file in os.scandir(label_train_dir):\n",
        "      os.remove(file.path)\n",
        "  if len(os.listdir(label_val_dir)) > 0:\n",
        "    for file in os.scandir(label_val_dir):\n",
        "      os.remove(file.path)\n",
        "  if len(os.listdir(label_test_dir)) > 0:\n",
        "    for file in os.scandir(label_test_dir):\n",
        "      os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training and validation\n",
        "train_split = 0.7\n",
        "val_split = 0.2\n",
        "test_split = 0.1\n",
        "\n",
        "# Run the function\n",
        "for i in range(10):\n",
        "  label_train_dir = os.path.join(TRAINING_DIR, str(i))\n",
        "  label_val_dir = os.path.join(VALIDATION_DIR, str(i))\n",
        "  label_test_dir = os.path.join(TEST_DIR, str(i))\n",
        "  split_data(SOURCE_DIR=os.path.join(source_path, str(i)),\n",
        "             TRAINING_DIR=label_train_dir,\n",
        "             VALIDATION_DIR=label_val_dir,\n",
        "             TEST_DIR=label_test_dir,\n",
        "             TRAIN_SPLIT=train_split,\n",
        "             VAL_SPLIT=val_split)\n",
        "\n",
        "# Check that the number of images matches the expected output\n",
        "for i in range(10):\n",
        "  print(f\"There are {len(os.listdir(os.path.join(TRAINING_DIR, str(i))))} images of {i} in the training set\")\n",
        "  print(f\"There are {len(os.listdir(os.path.join(VALIDATION_DIR, str(i))))} images of {i} in the validation set\")\n",
        "  print(f\"There are {len(os.listdir(os.path.join(TEST_DIR, str(i))))} images of {i} in the test set\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcjoKI2qDHUF"
      },
      "source": [
        "## Step 3: Create Data Generators with Augmentation\n",
        "\n",
        "Now that you've organized the data properly, it's time to create **data generators** that will:\n",
        "\n",
        "1. **Load images in batches** (memory efficient)\n",
        "2. **Apply real-time augmentation** during training\n",
        "3. **Standardize image sizes** to a consistent resolution\n",
        "\n",
        "### Key Parameters:\n",
        "\n",
        "- **`target_size=(224, 224)`**: Resizes all images to 224×224 pixels (standard for many CNN architectures)\n",
        "- **`class_mode='sparse'`**: Uses integer labels (0-9) instead of one-hot encoding\n",
        "- **`rescale=1./255`**: Normalizes pixel values from [0, 255] to [0, 1]\n",
        "\n",
        "### Data Augmentation Transformations (Training Only):\n",
        "\n",
        "- `rotation_range=40`: Random rotations up to ±40°\n",
        "- `width_shift_range=0.2`: Random horizontal shifts (20% of width)\n",
        "- `height_shift_range=0.2`: Random vertical shifts (20% of height)\n",
        "- `shear_range=0.2`: Random shearing transformations\n",
        "- `zoom_range=0.2`: Random zoom in/out (80%-120%)\n",
        "- `horizontal_flip=True`: Random horizontal flipping\n",
        "- `fill_mode='nearest'`: Fill strategy for pixels outside boundaries\n",
        "\n",
        "**Note:** Validation and test sets only receive rescaling (no augmentation) to ensure consistent evaluation.\n",
        "\n",
        "Run the cell below to create the generators:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwWN2YmEDHUG"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR, TEST_DIR):\n",
        "  \"\"\"\n",
        "  Creates the training and validation data generators\n",
        "\n",
        "  Args:\n",
        "    TRAINING_DIR (string): directory path containing the training images\n",
        "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
        "\n",
        "  Returns:\n",
        "    train_generator, validation_generator - tuple containing the generators\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class for the training set\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                     rotation_range=40,\n",
        "                                      width_shift_range=0.2,\n",
        "                                      height_shift_range=0.2,\n",
        "                                      shear_range=0.2,\n",
        "                                      zoom_range=0.2,\n",
        "                                      horizontal_flip=True,\n",
        "                                      fill_mode='nearest')\n",
        "  # only applying the rescale transformation to the validation and test sets\n",
        "  val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode='sparse',\n",
        "                                                      target_size=(224, 224))\n",
        "  validation_generator = val_test_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                              batch_size=32,\n",
        "                                                              class_mode='sparse',\n",
        "                                                              target_size=(224, 224))\n",
        "  test_generator = val_test_datagen.flow_from_directory(directory=TEST_DIR,\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='sparse',\n",
        "                                                        target_size=(224, 224))\n",
        "  return train_generator, validation_generator, test_generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUabcgC8DHUG",
        "outputId": "a7931810-c306-44e4-911f-d79289572f83"
      },
      "outputs": [],
      "source": [
        "# Test your generators\n",
        "train_generator, validation_generator, test_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR, TEST_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvdRBRlMDHUG"
      },
      "source": [
        "## Task 1: Design Your CNN Architecture\n",
        "\n",
        "**Objective:** Build a CNN model that achieves strong performance on the flower classification task.\n",
        "\n",
        "To pass this task, your model should:\n",
        "\n",
        "✅ **Test Accuracy**: ≥ 80% with `epochs` = 20.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzGtTciqDHUG"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: create_model\n",
        "def create_model():\n",
        "  \"\"\"\n",
        "  Creates a CNN model for flower classification.\n",
        "\n",
        "  Architecture:\n",
        "    - 4 Convolutional blocks with progressive filter increase (32→64→128→128)\n",
        "    - MaxPooling after each conv block for dimensionality reduction\n",
        "    - Dense layer with 512 units for high-level feature learning\n",
        "    - Output layer with 10 units (softmax) for 10-class classification\n",
        "\n",
        "  Returns:\n",
        "    Compiled Keras model ready for training\n",
        "  \"\"\"\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "\n",
        "    # start building the model here\n",
        "\n",
        "\n",
        "    # end building the model here\n",
        "  ])\n",
        "\n",
        "\n",
        "  # Compile with appropriate loss for multi-class classification\n",
        "\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j_c1pnTVDHUG",
        "outputId": "958c8ab9-14e3-414c-b6eb-6e5017104a5d"
      },
      "outputs": [],
      "source": [
        "# create the untrained model\n",
        "\n",
        "\n",
        "# Display model architecture\n",
        "\n",
        "\n",
        "# Count parameters\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kyIIQVeDHUG"
      },
      "source": [
        "### Visualize Training Progress\n",
        "\n",
        "Once training has finished, visualize the **training and validation metrics** across epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "id": "EXqZzc4mDHUG",
        "outputId": "2b64a42e-5058-4cb7-8c5c-c5ae1eb385e5"
      },
      "outputs": [],
      "source": [
        "# Extract training history\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "# Create a figure with two subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot 1: Accuracy\n",
        "ax1.plot(epochs_range, acc, 'r-', linewidth=2, label=\"Training Accuracy\")\n",
        "ax1.plot(epochs_range, val_acc, 'b-', linewidth=2, label=\"Validation Accuracy\")\n",
        "ax1.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Accuracy', fontsize=12)\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim([0, 1])\n",
        "\n",
        "# Plot 2: Loss\n",
        "ax2.plot(epochs_range, loss, 'r-', linewidth=2, label=\"Training Loss\")\n",
        "ax2.plot(epochs_range, val_loss, 'b-', linewidth=2, label=\"Validation Loss\")\n",
        "ax2.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Loss', fontsize=12)\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"  Training Summary\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"  Best Training Accuracy:   {max(acc):.4f} (epoch {acc.index(max(acc))+1})\")\n",
        "print(f\"  Best Validation Accuracy: {max(val_acc):.4f} (epoch {val_acc.index(max(val_acc))+1})\")\n",
        "print(f\"  Final Training Accuracy:  {acc[-1]:.4f}\")\n",
        "print(f\"  Final Validation Accuracy:{val_acc[-1]:.4f}\")\n",
        "print(f\"  Accuracy Gap (final):     {abs(acc[-1] - val_acc[-1]):.4f}\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In addition to reporting your training and validation accuracy above, please also include your test accuracy below. Finally, comment on whether your model shows signs of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rpzr1mADHUG",
        "outputId": "f740fcb8-6568-4691-9b88-148920ee86d3"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ⭐ Bonus Challenge: Achieve Test Accuracy Above 85%\n",
        "\n",
        "This task is **optional** — you may skip it if you prefer.\n",
        "\n",
        "If your model reaches **> 85% test accuracy**, you will earn **1 bonus point**(added to your total score) at the end!\n",
        "\n",
        "Feel free to experiment with:\n",
        "\n",
        "- Different model architectures\n",
        "- Optimizers & learning rate schedules\n",
        "- Regularization (dropout, batch norm, early stopping, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvpBPjgtDHUH"
      },
      "source": [
        "## Task 2: Experience Overfitting Without Data Augmentation\n",
        "\n",
        "Simply train the same model architecture **WITHOUT data augmentation** to observe the overfitting phenomenon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tC-6AenaDHUH"
      },
      "outputs": [],
      "source": [
        "def load_images_and_labels(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for label, class_name in enumerate(os.listdir(directory)):\n",
        "        class_dir = os.path.join(directory, class_name)\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            image = keras.preprocessing.image.load_img(\n",
        "                os.path.join(class_dir, image_name),\n",
        "                target_size=(224, 224)\n",
        "            )\n",
        "            image = keras.preprocessing.image.img_to_array(image)\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEQRV8qeDHUH"
      },
      "outputs": [],
      "source": [
        "# Load images and labels\n",
        "images, labels = load_images_and_labels('flowers')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9x0L--SDHUH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ24-R4wDHUH",
        "outputId": "c1f992df-e720-4b2e-b084-8e7b0ebd8178"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfWO9yeBDHUH",
        "outputId": "2fa57ee1-4005-4ac4-e867-eb4973c34d17"
      },
      "outputs": [],
      "source": [
        "# Get the untrained model\n",
        "model2 = create_model()\n",
        "\n",
        "# IMPORTANT: Normalize the training data (divide by 255)\n",
        "X_train_normalized = X_train / 255.0\n",
        "X_test_normalized = X_test / 255.0\n",
        "\n",
        "# Train the model (without data augmentation)\n",
        "history_2 = model2.fit(\n",
        "    X_train_normalized,\n",
        "    y_train,\n",
        "    epochs=20,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "id": "YUHWbzJGDHUH",
        "outputId": "2f9910f6-31db-4a11-ba58-555d30d95ba6"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history_2.history['accuracy']\n",
        "loss=history_2.history['loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
        "plt.title('Training accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_dqqcSrDHUH",
        "outputId": "3041b288-0a1d-46fa-c7a3-9f71b148cb34"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on test set\n",
        "test_loss, test_accuracy = model2.evaluate(X_test_normalized, y_test, verbose=0)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"  Final Training Accuracy: {history_2.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"  Final Test Accuracy:     {test_accuracy:.4f}\")\n",
        "print(f\"  Accuracy Gap:            {abs(history_2.history['accuracy'][-1] - test_accuracy):.4f}\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "if abs(history_2.history['accuracy'][-1] - test_accuracy) > 0.15:\n",
        "    print(\"\\n⚠️  OVERFITTING DETECTED!\")\n",
        "    print(\"   Training accuracy is much higher than test accuracy.\")\n",
        "    print(\"   This is why data augmentation is important!\")\n",
        "else:\n",
        "    print(\"\\n✓ Model generalizes well (minimal overfitting)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Summarize what you have learned from this notebook below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
